---
layout: single
title: "Projects"
permalink: /projects/
author_profile: true
classes: wide
header :
    image: "/assets/images/universe.jpg"
---

## Data Science

* **[Carrefour-X AI & Retail Challenge](https://github.com/jeremieperes/Hackathon-X-Carrefour-2020/) - Rank 1st: 10 weeks project building a local Marketing Mix Modeling – analysis and prediction of the impact of marketing media on sales (ROI)**

    ![Carrefour-X AI & Retail Challenge](/assets/images/carrefour_X_challenge.png?thumbnail)

    **Keywords:** *MMM, Interpretable ML, CatBoost, SHAP, GCP, Big Query, Dash*

    From 3rd February to 8th April 2020, I had the opportunity of participating in the X-Carrefour AI & Retail Challenge, a data science hackathon gathering 130 participants working on 3 specific thematics : Assortments / in-store offers, Marketing Mix Modeling  and Delivery Optimisation.

    With the help of Carrefour Data and Marketing Departments and over 30 datasets on Carrefour's products, customers, marketing investments and sales, **our team won the 1st prize** by building a Marketing Mix Modeling at a local granularity with a focus on organic products in order to isolate and anticipate the impact of the local marketing levers on organic sales.

    Our team managed to train a highly effective yet interpretable Machine Learning algorithm using [CatBoost](https://catboost.ai/) and [SHAP](https://github.com/slundberg/shap), build a dashboard for Carrefour Marketing teams to help them analyse the profitability of all marketing investments and give Carrefour concrete recommendations to help them become the world leader in the [« food transition »](https://actforfood.carrefour.fr/).

* **[LFIS-Dauphine Hackathon](https://github.com/jeremieperes/Team-JKVT-Datachallenge-Dauphine) - Rank 3rd: 24 hours data challenge predicting stock volatility among the S&P500 and Stoxx600 on performance announcement dates**

    **Keywords:** *LightGBM, Hyperopt, resampling (SMOTE)*

    On February 2020, I had the pleasure of participating in a [24 hours data challenge](https://www.qminitiative.org/hackathon2---intelligence-artificielle-&-machine-learning.html) organized by [LFIS](https://www.lfis.com/fr.html), [Sesamm](https://www.sesamm.com/) and [Dauphine Université Paris](https://dauphine.psl.eu/). The goal was to predict stock volatility among the S&P500 and Stoxx600 on performance announcement dates.

    Using advanced preprocessing and hyperparameters optimization techniques, **our team won the 3rd prize**.


## Data Engineering

* **[GDELT Project](https://github.com/jeremieperes/MongoDB-Gdelt): Built a resilient architecture for storing large amount of data from the GDELT database allowing fast responding queries**

    **Keywords:** *Spark, MongoDB, AWS, Zeppelin, ETL*

    **Environment:**  
    - ETL: Spark
    - Architecture: 3 MongoDB nodes on EC2
    - Visualization: Zeppelin + Python webapp

    ![Environment for GDELT project](/assets/images/gdelt.png)

## Data visualization

* **[French digital training courses - GitHub repo](https://github.com/jeremieperes/french-training-courses): Built a web app in Python providing an analysis of French online digital training market.**

    **Keywords:** *web scrapping, data visualization*

    Built a web app providing a statistical analysis of French digital training courses offered on the website / mobile app “Mon Compte Formation”, launched in November 2019 by the French Governement.


## IoT

* **[CentraleSupelec final year project - Piratage d’objets connectés (2017)](/assets/files/Rapport_Projet_IoT.pdf)**
